{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0SxJYyecodL/UOPPnqI/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharvaniyadav/Assignment-1-ECE1513-Intro-To-ML/blob/main/Assignment_1_ECE1513_IntroToML_SharvaniYadav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X2AntL4JgzRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a50caa-684a-4ed1-ca7b-9bcaede46ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DATASET LOADED ===\n",
            "Shape of X (rows, columns): (569, 30)\n",
            "First row of raw data (before standardization):\n",
            "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            " 4.601e-01 1.189e-01]\n",
            "\n",
            "=== AFTER STANDARDIZATION ===\n",
            "First row after standardization (values were now near 0):\n",
            "[ 1.097 -2.073  1.27   0.984  1.568  3.284  2.653  2.532  2.218  2.256\n",
            "  2.49  -0.565  2.833  2.488 -0.214  1.317  0.724  0.661  1.149  0.907\n",
            "  1.887 -1.359  2.304  2.001  1.308  2.617  2.11   2.296  2.751  1.937]\n",
            "\n",
            "Mean of first 5 features: [-0. -0. -0. -0.  0.]\n",
            "Std of first 5 features: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# Course: ECE1513 Introduction to Machine Learning (Fall 2025)\n",
        "# Assignment 1\n",
        "# Student Name: Sharvani Yadav\n",
        "# Student Number: 1008289870\n",
        "\n",
        "# Part 1: Clustering with k-means\n",
        "# This coded written below for Part 1 implements k-means clustering from scratch using only NumPy.\n",
        "# It uses an initialization method iscussed in class (sampled from the dataset) for reproducibility.\n",
        "# It will run the algorithm for k = 2..7, computes distortion, and plots an elbow curve.\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------\n",
        "# Part 1.1: Implemented k-means using a single initialization method (sampling points from dataset)\n",
        "# -------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Import needed libraries\n",
        "# numpy: for math with arrays\n",
        "# sklearn.datasets: to load the Breast Cancer dataset\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 1: Loaded the dataset\n",
        "# -----------------------------\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Loading the UCI ML Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Only needed the features (X) for clustering, not the labels\n",
        "X = data.data.astype(float)\n",
        "\n",
        "print(\"=== DATASET LOADED ===\")\n",
        "print(\"Shape of X (rows, columns):\", X.shape)   # should be 569 rows Ã— 30 features\n",
        "print(\"First row of raw data (before standardization):\")\n",
        "print(X[0])  # just to see the numbers before I change anything\n",
        "print()\n",
        "\n",
        "# -----------------------------\n",
        "# STEP 2: Made all features the same scale (standardized)\n",
        "# -----------------------------\n",
        "\n",
        "# Imported NumPy for math operations\n",
        "import numpy as np\n",
        "\n",
        "# Found the average (mean) value for each feature\n",
        "feature_means = X.mean(axis=0)\n",
        "\n",
        "# Found how spread out (standard deviation) each feature was\n",
        "feature_stds = X.std(axis=0, ddof=0)\n",
        "\n",
        "# Replaced any feature with zero spread with 1 to avoid dividing by zero\n",
        "feature_stds[feature_stds == 0] = 1.0\n",
        "\n",
        "# Created a new dataset where each feature had mean 0 and spread ~1\n",
        "# This was done by subtracting the mean and dividing by the standard deviation\n",
        "Xs = (X - feature_means) / feature_stds\n",
        "\n",
        "print(\"=== AFTER STANDARDIZATION ===\")\n",
        "print(\"First row after standardization (values were now near 0):\")\n",
        "print(np.round(Xs[0], 3))  # Rounded to make it easier to read\n",
        "\n",
        "# Checked that the first few features had mean close to 0 and std close to 1\n",
        "print(\"\\nMean of first 5 features:\", np.round(Xs[:, :5].mean(axis=0), 3))\n",
        "print(S\"Std of first 5 features:\", np.round(Xs[:, :5].std(axis=0, ddof=0), 3))\n",
        "\n",
        "\n"
      ]
    }
  ]
}